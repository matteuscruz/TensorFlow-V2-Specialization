{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vYuwZ2RbEeVt",
        "Pp7O5DjkEeVv",
        "wyz7GDVFEeVv",
        "QcaMK7gpEeVz",
        "kQ0YBtuuEeV0",
        "_yKoCSaoEeV1",
        "ctYQv5dCEeV1",
        "RoTOrYGkEeV1",
        "2OuPQ3GTEeV2",
        "OZx5x3Y8EeV3",
        "9fNsQMBwEeV4",
        "5LIs52-OEeV5",
        "PvVPSaokEeV7",
        "lVohCUubEeV8",
        "6jCZmjSSEeV8",
        "gOib_Ny0EeV9",
        "Y92kr7WnEeV9",
        "Qu25rzrREeV-",
        "WkvBV4sQEeV_",
        "WFRRtfWJEeWA",
        "R7ck5fkOEeWA",
        "QiCYBCSEEeWG",
        "iFOyo6cHEeWG",
        "1MZFTCY0EeWH",
        "8nZQX_faEeWH",
        "4af-69JZEeWI",
        "OHpCqCx9EeWI",
        "kSmgDaSPEeWJ",
        "mxDuIQ8MEeWJ"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteuscruz/TensorFlow-V2-Specialization/blob/main/Keras_image_data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WtHzzdAEeVl"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1YMviZcEeVq"
      },
      "source": [
        "# Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35OO6xwgEeVq"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Keras datasets](#coding_tutorial_1)\n",
        " #### [2. Dataset generators](#coding_tutorial_2)\n",
        " #### [3. Keras image data augmentation](#coding_tutorial_3)\n",
        " #### [4. The Dataset class](#coding_tutorial_4)\n",
        " #### [5. Training with Datasets](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw8tYJ3BEeVr"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Keras datasets\n",
        "\n",
        "For a list of Keras datasets and documentation on recommended usage, see [this link](https://keras.io/datasets/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpDutlgmEeVr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ-5izZVEeVr"
      },
      "source": [
        "#### Load the CIFAR-100 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFxY1GTAEeVr"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d4fUzAx-EeVs"
      },
      "source": [
        "# Load the CIFAR-100 dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLlpkea7EeVs"
      },
      "source": [
        "# Confirm that reloading the dataset does not require a download\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG5mmgcUEeVs"
      },
      "source": [
        "#### Examine the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUIPhuIUEudr"
      },
      "source": [
        "#### Import the Data\n",
        "\n",
        "The additional files required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "cifar100_fine_labels: https://drive.google.com/open?id=1WFW1cj8v_5z1pGvq6htQyFUPrJP-Z2v5\n",
        "\n",
        "cifar100_coarse_labels: https://drive.google.com/open?id=1Jmt7o-6sP85D7iRORk5tJqJMN3wCP12p\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy01Y6TVEvKh"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgurBwKFEeVs"
      },
      "source": [
        "# Examine the shape of the data.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH1I1Ju4EeVs"
      },
      "source": [
        "# Examine one of the images and its corresponding label\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c--LIL8QEeVt"
      },
      "source": [
        "# Load the list of labels from a JSON file\n",
        "# Please use your own path once you have downloaded the .json file and mounted your Drive\n",
        "\n",
        "import json\n",
        "\n",
        "with open('your_gdrive/cifar100_fine_labels.json', 'r') as fine_labels:\n",
        "    cifar100_fine_labels = json.load(fine_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nvw8QflEeVt"
      },
      "source": [
        "The list of labels for the CIFAR-100 dataset are available [here](https://www.cs.toronto.edu/~kriz/cifar.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivOPZM6LEeVt"
      },
      "source": [
        "# Print a few of the labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBOwB5WcEeVt"
      },
      "source": [
        "# Print the corresponding label for the example above\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYuwZ2RbEeVt"
      },
      "source": [
        "#### Load the data using different label modes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZl1a6r4EeVt"
      },
      "source": [
        "# Display a few examples from category 87 (index 86) and the list of labels\n",
        "\n",
        "examples = train_images[(train_labels.T == 86)[0]][:3]\n",
        "fig, ax = plt.subplots(1,3)\n",
        "ax[0].imshow(examples[0])\n",
        "ax[1].imshow(examples[1])\n",
        "ax[2].imshow(examples[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBuq2_uEeVu"
      },
      "source": [
        "# Reload the data using the 'coarse' label mode\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtE80saCEeVu"
      },
      "source": [
        "# Display three images from the dataset with the label 6 (index 5)\n",
        "\n",
        "examples = train_images[(train_labels.T == 5)[0]][:3]\n",
        "fig, ax = plt.subplots(1,3)\n",
        "ax[0].imshow(examples[0])\n",
        "ax[1].imshow(examples[1])\n",
        "ax[2].imshow(examples[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbNm2gp3EeVu"
      },
      "source": [
        "# Load the list of coarse labels from a JSON file\n",
        "\n",
        "with open('data/cifar100_coarse_labels.json', 'r') as coarse_labels:\n",
        "    cifar100_coarse_labels = json.load(coarse_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_TfO3pnAEeVu"
      },
      "source": [
        "# Print a few of the labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4eYoJVaEeVu"
      },
      "source": [
        "# Print the corresponding label for the example above\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp7O5DjkEeVv"
      },
      "source": [
        "#### Load the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll2lib6oEeVv"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAU-4AXFEeVv"
      },
      "source": [
        "# Load the IMDB dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YfUEN-rEeVv"
      },
      "source": [
        "# Print an example from the training dataset, along with its corresponding label\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_bbZNdgEeVv"
      },
      "source": [
        "# Get the lengths of the input sequences\n",
        "\n",
        "sequence_lengths = [len(seq) for seq in train_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoID1BoqEeVv"
      },
      "source": [
        "# Determine the maximum and minimum sequence length\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyz7GDVFEeVv"
      },
      "source": [
        "#### Using Keyword Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJWyBIPzEeVw"
      },
      "source": [
        "# Load the data ignoring the 50 most frequent words, use oov_char=2 (this is the default)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT-w9vrkEeVw"
      },
      "source": [
        "# Get the lengths of the input sequences\n",
        "\n",
        "sequence_lengths = [len(seq) for seq in train_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayc0lswSEeVw"
      },
      "source": [
        "# Determine the maximum and minimum sequence length\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW2LIQzyEeVw"
      },
      "source": [
        "# Define functions for filtering the sequences\n",
        "\n",
        "def remove_oov_char(element):\n",
        "    ''' Filter function for removing the oov_char. '''\n",
        "    return [word for word in element if word!=2]\n",
        "\n",
        "def filter_list(lst):\n",
        "    ''' Run remove_oov_char on elements in a list. '''\n",
        "    return [remove_oov_char(element) for element in lst]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dROgLobEeVw"
      },
      "source": [
        "# Remove the oov_char from the sequences using the filter_list function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7mc9QfDEeVw"
      },
      "source": [
        "# Get the lengths of the input sequences\n",
        "\n",
        "sequence_lengths = [len(seq) for seq in train_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq_6LHcYEeVw"
      },
      "source": [
        "# Determine the maximum and minimum sequence length\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea9mLdxpEeVx"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Dataset generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSrltRszEeVx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r630XHVtEeVx"
      },
      "source": [
        "#### Load the UCI Fertility Dataset\n",
        "\n",
        "We will be using a dataset available at https://archive.ics.uci.edu/ml/datasets/Fertility from UC Irvine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te2kRA79GF-j"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=1OA0lwa5YLDs1njS377jbqPpMSlH5TzQV\n",
        "\n",
        "You should store this file in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJEDaHV9GKNL"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDtrr1dcEeVx"
      },
      "source": [
        "# Load the fertility dataset\n",
        "# Please use your own path once you have downloaded the dataset and mounted your Drive\n",
        "\n",
        "headers = ['Season', 'Age', 'Diseases', 'Trauma', 'Surgery', 'Fever', 'Alcohol', 'Smoking', 'Sitting', 'Output']\n",
        "fertility = pd.read_csv('your_gdrive/fertility_diagnosis.txt', delimiter=',', header=None, names=headers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnnc0TN5EeVx"
      },
      "source": [
        "# Print the shape of the DataFrame\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU5wKvaaEeVx"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X8Dsk0dEeVx"
      },
      "source": [
        "#### Process the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC-f3k2yEeVy"
      },
      "source": [
        "# Map the 'Output' feature from 'N' to 0 and from 'O' to 1\n",
        "\n",
        "fertility['Output'] = fertility['Output'].map(lambda x : 0.0 if x=='N' else 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsS9OG3lEeVy"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQxgr1lWEeVy"
      },
      "source": [
        "# Convert the DataFrame so that the features are mapped to floats\n",
        "\n",
        "fertility = fertility.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn4zFUY8EeVy"
      },
      "source": [
        "# Shuffle the DataFrame\n",
        "\n",
        "fertility = fertility.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8qCogWNsEeVy"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRXzGKitEeVy"
      },
      "source": [
        "# Convert the field Season to a one-hot encoded vector\n",
        "\n",
        "fertility = pd.get_dummies(fertility, prefix='Season', columns=['Season'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSp-M4_XEeVy"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omggmC8OEeVz"
      },
      "source": [
        "*N.B. The below cell has been updated since the coding tutorial.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cjxNq8VEeVz"
      },
      "source": [
        "# Move the Output column such that it is the last column in the DataFrame\n",
        "\n",
        "fertility = fertility.reindex(columns = [col for col in fertility.columns if col != 'Output'] + ['Output'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukLlV7jKEeVz"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "fertility.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgW9zEJ6EeVz"
      },
      "source": [
        "# Convert the DataFrame to a numpy array.\n",
        "\n",
        "fertility = fertility.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcaMK7gpEeVz"
      },
      "source": [
        "#### Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBDxQEafEeV0"
      },
      "source": [
        "# Split the dataset into training and validation set\n",
        "\n",
        "training = fertility[0:70]\n",
        "validation = fertility[70:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MCbZolDEeV0"
      },
      "source": [
        "# Verify the shape of the training data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcVDlrZNEeV0"
      },
      "source": [
        "# Separate the features and labels for the validation and training data\n",
        "\n",
        "training_features = training[:,0:-1]\n",
        "training_labels = training[:,-1]\n",
        "validation_features = validation[:,0:-1]\n",
        "validation_labels = validation[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ0YBtuuEeV0"
      },
      "source": [
        "#### Create the Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wuc3YbFEeV0"
      },
      "source": [
        "# Create a function that returns a generator producing inputs and labels\n",
        "\n",
        "def get_generator(features, labels, batch_size=1):\n",
        "    for n in range(int(len(features)/batch_size)):\n",
        "        yield (features[n*batch_size: (n+1)*batch_size], labels[n*batch_size: (n+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcZo4UTwEeV0"
      },
      "source": [
        "# Apply the function to our training features and labels with a batch size of 10\n",
        "\n",
        "train_generator = get_generator(training_features, training_labels, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEI5Q2O_EeV0"
      },
      "source": [
        "# Test the generator using the next() function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yKoCSaoEeV1"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cTLZKmJEeV1"
      },
      "source": [
        "# Create a model using Keras with 3 layers\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization\n",
        "\n",
        "input_shape = (12,)\n",
        "output_shape = (1,)\n",
        "\n",
        "model_input = Input(input_shape)\n",
        "batch_1 = BatchNormalization(momentum=0.8)(model_input)\n",
        "dense_1 = Dense(100, activation='relu')(batch_1)\n",
        "batch_2 = BatchNormalization(momentum=0.8)(dense_1)\n",
        "output = Dense(1, activation='sigmoid')(batch_2)\n",
        "\n",
        "model = Model([model_input], output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2t1F8ooEeV1"
      },
      "source": [
        "# Display the model summary to show the resultant structure\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctYQv5dCEeV1"
      },
      "source": [
        "#### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqo9wnHfEeV1"
      },
      "source": [
        "# Create the optimizer object\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClVftEzdEeV1"
      },
      "source": [
        "# Compile the model with loss function and metric\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoTOrYGkEeV1"
      },
      "source": [
        "#### Train and evaluate the model using the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOdcuOsCEeV1"
      },
      "source": [
        "# Calculate the number of training steps per epoch for the given batch size.\n",
        "\n",
        "batch_size = 5\n",
        "train_steps = len(training) // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkSU8bdLEeV2"
      },
      "source": [
        "# Set the epochs to 3\n",
        "\n",
        "epochs = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQWN4GpbEeV2"
      },
      "source": [
        "# Train the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "K2xcf_s4EeV2"
      },
      "source": [
        "# Try to run the fit_generator function once more; observe what happens\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=train_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OuPQ3GTEeV2"
      },
      "source": [
        "#### Make an infinitely looping generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_9X23g1EeV2"
      },
      "source": [
        "# Create a function that returns an infinitely looping generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V23QPRaKEeV2"
      },
      "source": [
        "# Create a generator using this function.\n",
        "\n",
        "train_generator_cyclic = get_generator_cyclic(training_features, training_labels, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz4VSofgEeV2"
      },
      "source": [
        "# Assert that the new cyclic generator does not raise a StopIteration\n",
        "\n",
        "for i in range(2*train_steps):\n",
        "    next(train_generator_cyclic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxVIm0qDEeV3"
      },
      "source": [
        "# Generate a cyclic validation generator\n",
        "\n",
        "validation_generator_cyclic = get_generator_cyclic(validation_features, validation_labels, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X1-t1EuxEeV3"
      },
      "source": [
        "# Train the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZx5x3Y8EeV3"
      },
      "source": [
        "#### Evaluate the model and get predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWnZiSB4EeV3"
      },
      "source": [
        "# Let's obtain a validation data generator.\n",
        "\n",
        "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTPGc-BlEeV3"
      },
      "source": [
        "# Get predictions on the validation data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eHZyWaDLEeV3"
      },
      "source": [
        "# Print the corresponding validation labels\n",
        "\n",
        "print(validation_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gUGTe1EeV3"
      },
      "source": [
        "# Obtain a validation data generator\n",
        "\n",
        "validation_generator = get_generator(validation_features, validation_labels, batch_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBh5w81YEeV3"
      },
      "source": [
        "# Evaluate the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2EsmU0SEeV4"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Keras image data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCoE2XtGGOA1"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=11Y43ta5gT672L3sfJFR2DvPs-ralY5Pd\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fX_TiG7GPvJ"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoVdDo0QEeV4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPskCs2eEeV4"
      },
      "source": [
        "#### Load the CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HFwq3_IEeV4"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDoFI82rEeV4"
      },
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "\n",
        "(training_features, training_labels), (test_features, test_labels) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oya1M870EeV4"
      },
      "source": [
        "# Convert the labels to a one-hot encoding\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "training_labels = tf.keras.utils.to_categorical(training_labels, num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fNsQMBwEeV4"
      },
      "source": [
        "#### Create a generator function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnM6_AabEeV4"
      },
      "source": [
        "# Create a function that returns a data generator\n",
        "\n",
        "def get_generator(features, labels, batch_size=1):\n",
        "    for n in range(int(len(features)/batch_size)):\n",
        "        yield (features[n*batch_size:(n+1)*batch_size], labels[n*batch_size:(n+1)*batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_sZ25Z6EeV5"
      },
      "source": [
        "# Use the function we created to get a training data generator with a batch size of 1\n",
        "\n",
        "training_generator = get_generator(training_features, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhzDsP0iEeV5"
      },
      "source": [
        "# Assess the shape of the items generated by training_generator using the `next` function to yield an item.\n",
        "\n",
        "image, label = next(training_generator)\n",
        "print(image.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbBu8SgAEeV5"
      },
      "source": [
        "# Test the training generator by obtaining an image using the `next` generator function, and then using imshow to plot it.\n",
        "# Print the corresponding label\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "image, label = next(training_generator)\n",
        "image_unbatched = image[0,:,:,:]\n",
        "imshow(image_unbatched)\n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzwWvAiPEeV5"
      },
      "source": [
        "# Reset the generator by re-running the `get_generator` function.\n",
        "\n",
        "train_generator = get_generator(training_features, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LIs52-OEeV5"
      },
      "source": [
        "#### Create a data augmentation generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GdN7QoeEeV5"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJYhARomEeV6"
      },
      "source": [
        "# Create a function to convert an image to monochrome\n",
        "\n",
        "def monochrome(x):\n",
        "    def func_bw(a):\n",
        "        average_colour = np.mean(a)\n",
        "        return [average_colour, average_colour, average_colour]\n",
        "    x = np.apply_along_axis(func_bw, -1, x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb18jt8MEeV6"
      },
      "source": [
        "# Create an ImageDataGenerator object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWcC_gjeEeV6"
      },
      "source": [
        "Check [the documentation](https://keras.io/preprocessing/image/) for the full list of image data augmentation options. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkTR68VhEeV6"
      },
      "source": [
        "# Create an iterable generator using the `flow` function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vdwnoN1wEeV6"
      },
      "source": [
        "# Show a sample from the generator and compare with the original\n",
        "\n",
        "image, label = next(image_generator_iterable)\n",
        "image_orig, label_orig = next(train_generator)\n",
        "figs, axes = plt.subplots(1,2)\n",
        "axes[0].imshow(image[0,:,:,:])\n",
        "axes[0].set_title('Transformed')\n",
        "axes[1].imshow(image_orig[0,:,:,:])\n",
        "axes[1].set_title('Original')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--SThzACEeV6"
      },
      "source": [
        "#### Flow from directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvbJ-DutEeV6"
      },
      "source": [
        "# Inspect the directory structure\n",
        "# Please use your own path once you have downloaded the dataset and mounted your Drive\n",
        "\n",
        "train_path = 'your_gdrive/flowers-recognition-split/train'\n",
        "val_path = 'your_gdrive/flowers-recognition-split/val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_slWTwewEeV7"
      },
      "source": [
        "# Create an ImageDataGenerator object\n",
        "\n",
        "datagenerator = ImageDataGenerator(rescale=(1/255.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Qbvbm2EeV7"
      },
      "source": [
        "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDoVAfLTEeV7"
      },
      "source": [
        "# Create a training data generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1GM0Q2mEeV7"
      },
      "source": [
        "# Create a validation data generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00aPXL7eEeV7"
      },
      "source": [
        "# Get and display an image and label from the training generator\n",
        "\n",
        "x = next(train_generator)\n",
        "imshow(x[0][4])\n",
        "print(x[1][4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq5eVcxCEeV7"
      },
      "source": [
        "# Reset the training generator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvVPSaokEeV7"
      },
      "source": [
        "#### Create a model to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Bw8N0TvQEeV7"
      },
      "source": [
        "# Build a CNN model\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Input((16,16,3)))\n",
        "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((4,4)))\n",
        "model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(4, (4, 4), padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9VnT5ZbEeV8"
      },
      "source": [
        "# Create an optimizer object\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trhVyod1EeV8"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhj3ae9mEeV8"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVohCUubEeV8"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWSTKDBuEeV8"
      },
      "source": [
        "# Calculate the training generator and test generator steps per epoch\n",
        "\n",
        "train_steps_per_epoch = train_generator.n // train_generator.batch_size\n",
        "val_steps = val_generator.n // val_generator.batch_size\n",
        "print(train_steps_per_epoch, val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN92Cz7qEeV8"
      },
      "source": [
        "# Fit the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jCZmjSSEeV8"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QxZVyFbEeV8"
      },
      "source": [
        "# Evaluate the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOib_Ny0EeV9"
      },
      "source": [
        "#### Predict using the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz38BrsrEeV9"
      },
      "source": [
        "# Predict labels with the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq5yEAJREeV9"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Dataset Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVy3yC6aGdfi"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=1BAjGPFlpqsDdWof50Ng3Fmju5O8F1_uZ\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIcWGhBYGfwk"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWNIHVSUEeV9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y92kr7WnEeV9"
      },
      "source": [
        "#### Create a simple dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHLwL0a3EeV9"
      },
      "source": [
        "x = np.zeros((100,10,2,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z72_ShgREeV9"
      },
      "source": [
        "# Create a dataset from the tensor x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSPcILGZEeV9"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WFfOYCeEeV-"
      },
      "source": [
        "x2 = [np.zeros((10,2,2)), np.zeros((5,2,2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTCBCrDeEeV-"
      },
      "source": [
        "# Try creating a dataset from the tensor x2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDtVyGwfEeV-"
      },
      "source": [
        "x2 = [np.zeros((10,1)), np.zeros((10,1)), np.zeros((10,1))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXSiD7_TEeV-"
      },
      "source": [
        "# Create another dataset from the new x2 and inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do4wCZXzEeV-"
      },
      "source": [
        "# Print the element_spec\n",
        "\n",
        "print(dataset2.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu25rzrREeV-"
      },
      "source": [
        "#### Create a zipped dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn11lRhrEeV-"
      },
      "source": [
        "# Combine the two datasets into one larger dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHfm_yvzEeV-"
      },
      "source": [
        "# Print the element_spec\n",
        "\n",
        "print(dataset_zipped.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viTfVlfBEeV_"
      },
      "source": [
        "# Define a function to find the number of batches in a dataset\n",
        "\n",
        "def get_batches(dataset):\n",
        "    iter_dataset = iter(dataset)\n",
        "    i = 0\n",
        "    try:\n",
        "        while next(iter_dataset):\n",
        "            i = i+1\n",
        "    except:\n",
        "        return i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFkarPs9EeV_"
      },
      "source": [
        "# Find the number of batches in the zipped Dataset\n",
        "\n",
        "get_batches(dataset_zipped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkvBV4sQEeV_"
      },
      "source": [
        "#### Create a dataset from numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qo4CEQNEeV_"
      },
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "(train_features, train_labels), (test_features, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(type(train_features), type(train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOjCtWwtEeV_"
      },
      "source": [
        "# Create a Dataset from the MNIST data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsB-nV7KEeV_"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n",
        "print(mnist_dataset.element_spec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awsMdgeZEeV_"
      },
      "source": [
        "# Inspect the length of an element using the take method\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51unsB7LEeV_"
      },
      "source": [
        "# Examine the shapes of the data\n",
        "\n",
        "print(element[0].shape)\n",
        "print(element[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFRRtfWJEeWA"
      },
      "source": [
        "#### Create a dataset from text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ZpK2qpEeWA"
      },
      "source": [
        "# Print the list of text files\n",
        "\n",
        "text_files = sorted([f.path for f in os.scandir('data/shakespeare')])\n",
        "\n",
        "print(text_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCcTp2bHEeWA"
      },
      "source": [
        "# Load the first file using python and print the first 5 lines.\n",
        "\n",
        "with open(text_files[0], 'r') as fil:\n",
        "    contents = [fil.readline() for i in range(5)]\n",
        "    for line in contents:\n",
        "        print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RR4XxJ2EeWA"
      },
      "source": [
        "# Load the lines from the files into a dataset using TextLineDataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLqjJBeBEeWA"
      },
      "source": [
        "# Use the take method to get and print the first 5 lines of the dataset\n",
        "\n",
        "first_5_lines_dataset = iter(shakespeare_dataset.take(5))\n",
        "lines = [line for line in first_5_lines_dataset]\n",
        "for line in lines:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIhYAGsEEeWA"
      },
      "source": [
        "# Compute the number of lines in the first file\n",
        "\n",
        "lines = []\n",
        "with open(text_files[0], 'r') as fil:\n",
        "    line = fil.readline()\n",
        "    while line:\n",
        "        lines.append(line)\n",
        "        line = fil.readline()\n",
        "    print(len(lines))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvBb0u4UEeWA"
      },
      "source": [
        "# Compute the number of lines in the shakespeare dataset we created\n",
        "\n",
        "shakespeare_dataset_iterator = iter(shakespeare_dataset)\n",
        "lines = [line for line in shakespeare_dataset_iterator]\n",
        "print(len(lines))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7ck5fkOEeWA"
      },
      "source": [
        "#### Interleave lines from the text data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cTtQV5kdEeWE"
      },
      "source": [
        "# Create a dataset of the text file strings\n",
        "\n",
        "text_files_dataset = tf.data.Dataset.from_tensor_slices(text_files)\n",
        "files = [file for file in text_files_dataset]\n",
        "for file in files:\n",
        "    print(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWLOpEcWEeWE"
      },
      "source": [
        "# Interleave the lines from the text files\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm5ycl5sEeWE"
      },
      "source": [
        "# Print the first 10 elements of the interleaved dataset\n",
        "\n",
        "lines = [line for line in iter(interleaved_shakespeare_dataset.take(10))]\n",
        "for line in lines:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxszgPiKEeWF"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Training with Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yminVIuREeWF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDarCW20EeWF"
      },
      "source": [
        "#### Load the UCI Bank Marketing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM3_YgDJGj8c"
      },
      "source": [
        "#### Import the data\n",
        "\n",
        "The dataset required for this tutorial can be downloaded from the following link:\n",
        "\n",
        "https://drive.google.com/open?id=1cNtP4iDyGhF620ZbmJdmJWYQrRgJTCum\n",
        "\n",
        "You should store these files in Drive for use in this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saF_YbpoGljW"
      },
      "source": [
        "# Run this cell to connect to your Drive folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GK4xBgaEeWF"
      },
      "source": [
        "# Load the CSV file into a pandas DataFrame\n",
        "# Please use your own path once you have downloaded the dataset and mounted your Drive\n",
        "\n",
        "bank_dataframe = pd.read_csv('your_gdrive/bank/bank-full.csv', delimiter=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ea2BykyVEeWF"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "bank_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2LydULyEeWF"
      },
      "source": [
        "# Print the shape of the DataFrame\n",
        "\n",
        "print(bank_dataframe.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-OO_CQUEeWF"
      },
      "source": [
        "# Select features from the DataFrame\n",
        "\n",
        "features = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
        "            'loan', 'contact', 'campaign', 'pdays', 'poutcome']\n",
        "labels = ['y']\n",
        "\n",
        "bank_dataframe = bank_dataframe.filter(features + labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "G9FRJpAzEeWG"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "bank_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiCYBCSEEeWG"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhbcaYpIEeWG"
      },
      "source": [
        "# Convert the categorical features in the DataFrame to one-hot encodings\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "categorical_features = ['default', 'housing', 'job', 'loan', 'education', 'contact', 'poutcome']\n",
        "\n",
        "for feature in categorical_features:\n",
        "    bank_dataframe[feature] = tuple(encoder.fit_transform(bank_dataframe[feature]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XtxOVZqSEeWG"
      },
      "source": [
        "# Show the head of the DataFrame\n",
        "\n",
        "bank_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuJVOzqBEeWG"
      },
      "source": [
        "*N.B. The below cell has been updated to correct the name of a variable and differs from the Coding Tutorial video.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVC2hNiZEeWG"
      },
      "source": [
        "# Shuffle the DataFrame\n",
        "\n",
        "bank_dataframe = bank_dataframe.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFOyo6cHEeWG"
      },
      "source": [
        "#### Create the Dataset object\n",
        "\n",
        "*N.B. Please use ``bank_dataframe.to_dict(orient='list')`` to convert the correct dataframe to a dictionary suitable for use in the ``from_tensor_slices`` function, rather than ``dict(dataframe)`` as specified in the coding tutorial video.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-ONCYvhEeWG"
      },
      "source": [
        "# Convert the DataFrame to a Dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZnXio4AEeWH"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MZFTCY0EeWH"
      },
      "source": [
        "#### Filter the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsLbjbyHEeWH"
      },
      "source": [
        "# First check that there are records in the dataset for non-married individuals\n",
        "\n",
        "def check_divorced():\n",
        "    bank_dataset_iterable = iter(bank_dataset)\n",
        "    for x in bank_dataset_iterable:\n",
        "        if x['marital'] != 'divorced':\n",
        "            print('Found a person with marital status: {}'.format(x['marital']))\n",
        "            return\n",
        "    print('No non-divorced people were found!')\n",
        "\n",
        "check_divorced()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Yq0oJyEeWH"
      },
      "source": [
        "# Filter the Dataset to retain only entries with a 'divorced' marital status\n",
        "\n",
        "bank_dataset = bank_dataset.filter(lambda x : tf.equal(x['marital'], tf.constant([b'divorced']))[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVWusKq3EeWH"
      },
      "source": [
        "# Check the records in the dataset again\n",
        "\n",
        "check_divorced()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nZQX_faEeWH"
      },
      "source": [
        "#### Map a function over the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgfIsK3rEeWH"
      },
      "source": [
        "# Convert the label ('y') to an integer instead of 'yes' or 'no'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMbbvVzHEeWH"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n",
        "bank_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ss_F9vJEeWI"
      },
      "source": [
        "# Remove the 'marital' column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZx5LpboEeWI"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n",
        "bank_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4af-69JZEeWI"
      },
      "source": [
        "#### Create input and output data tuples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIGiLFvfEeWI"
      },
      "source": [
        "# Create an input and output tuple for the dataset\n",
        "\n",
        "def map_feature_label(x):\n",
        "    features = [[x['age']], [x['balance']], [x['campaign']], x['contact'], x['default'],\n",
        "                x['education'], x['housing'], x['job'], x['loan'], [x['pdays']], x['poutcome']]\n",
        "    return (tf.concat(features, axis=0), x['y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SeKL8ROlEeWI"
      },
      "source": [
        "# Map this function over the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7CirL-aEeWI"
      },
      "source": [
        "# Inspect the Dataset object\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHpCqCx9EeWI"
      },
      "source": [
        "#### Split into a training and a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v-OyCRTEeWJ"
      },
      "source": [
        "# Determine the length of the Dataset\n",
        "\n",
        "dataset_length = 0\n",
        "for _ in bank_dataset:\n",
        "    dataset_length += 1\n",
        "print(dataset_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoriUbd5EeWJ"
      },
      "source": [
        "# Make training and validation sets from the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSmgDaSPEeWJ"
      },
      "source": [
        "#### Build a classification model\n",
        "\n",
        "Now let's build a model to classify the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zF8XfuUEeWJ"
      },
      "source": [
        "# Build a classifier model\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(30,)))\n",
        "model.add(BatchNormalization(momentum=0.8))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(BatchNormalization(momentum=0.8))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(BatchNormalization(momentum=0.8))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tHFwvrXEeWJ"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4TOTFf45EeWJ"
      },
      "source": [
        "# Show the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxDuIQ8MEeWJ"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khxbc3sVEeWJ"
      },
      "source": [
        "# Create batched training and validation datasets\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNTRx7cXEeWK"
      },
      "source": [
        "# Shuffle the training data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RnXvb-spEeWK"
      },
      "source": [
        "# Fit the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JCa9cnmEeWK"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}